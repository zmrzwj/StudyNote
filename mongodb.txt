0.简介
1）MongoDB 是一个高性能，开源，无模式的文档型数据库，是当前 NoSQL 数据库产品中最热门的一种。它在许多场景下可用于替代传统的关系型数据库或键/值存储方式，MongoDB 使用 C++开发。
什么情况使用mongodb:
更高的写入负载
高可用性
数据量很大或者未来会变得很大
表结构不明确，且数据在不断变大

2）RDBMS缺点：
当数据量越来越大，RDBMS数据库撑不住了，就出现了读写分离策略，通过一个Master专门负责写操作，多个Slave负责读操作，服务器成本倍增。随着压力增加，Master撑不住了，这时就要分库了，把关联不大的数据分开部署，一些join查询不能用了，需要借助中间层。随着数据量的进一步增加，一个表的记录越来越大，查询就变得很慢，于是又得搞分表，比如按ID取模分成多个表以减少单个表的记录数。

3）适用场景
网站数据：适合实时的插入，更新与查询，并具备网站实时数据存储所需的复制及高度伸缩性。
缓存：由于性能很高，也适合作为信息基础设施的缓存层。在系统重启之后，搭建的持久化缓存可以避免下层的数据源过载。
大尺寸、低价值的数据：使用传统的关系数据库存储一些数据时可能会比较贵，在此之前，很多程序员往往会选择传统的文件进行存储。
高伸缩性的场景：非常适合由数十或者数百台服务器组成的数据库。
用于对象及JSON数据的存储：MongoDB的BSON数据格式非常适合文档格式化的存储及查询。

4）应用案例
（1）京东,中国著名电商,使用MongoDB存储商品信息,支持比价和关注功能。
（2）赶集网,中国著名分类信息网站,使用MongoDB记录pv浏览计数。
（3）奇虎360,著名病毒软件防护和移动应用平台,使用MongoBD支撑的HULK平台每天接受200亿次的查询。
（4）百度云,使用MongoDB管理百度云盘中500亿条关于文件源信息的记录。
（5）CERN，著名的粒子物理研究所，欧洲核子研究中心大型强子对撞机的数据使用MongoDB。
（6）纽约时报，领先的在线新闻门户网站之一，使用MongoDB。
（7）sourceforge.net，资源网站查找，创建和发布开源软件免费，使用MongoDB的后端存储。
（8）游戏场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便查询、更新。
（9）物流场景，使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来。
（10）社交场景，使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能。
（11）物联网场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析
视频直播，使用 MongoDB 存储用户信息、礼物信息等。

5）应用特征	Yes / No
应用不需要事务及复杂 join 支持	必须 Yes
新应用，需求会变，数据模型无法确定，想快速迭代开发	？
应用需要2000-3000以上的读写QPS（更高也可以）	？
应用需要TB甚至 PB 级别数据存储	?
应用发展迅速，需要能快速水平扩展	?
应用要求存储的数据不丢失	?
应用需要99.999%高可用	?
应用需要大量的地理位置查询、文本查询	？
如果上述有1个 Yes，可以考虑 MongoDB，2个及以上的 Yes，选择MongoDB绝不会后悔。







1.mongodb安装
1)下载：https://www.mongodb.com/download-center/community
下载：mongodb-linux-x86_64-4.0.6.tgz
tar -zxvf mongodb-linux-x86_64-4.0.6.tgz
Mv mongodb-linux-x86_64-4.0.6 mongodb
vi /etc/profile 添加环境变量
mongodb目录下新建一个名为db的文件夹，用来存放数据库
mongodb目录下新建一个名为logs的文件夹，用来存放日志

2)配置
cd mongodb/bin
vim mongodb.conf
# 设置端口号（默认的端口号是 27017）
port=27017
# 设置数据文件的存放目录
dbpath = /usr/local/mongodb/db
# 设置为以守护进程的方式运行，即在后台运行
fork = true
# 设置日志文件的存放目录及其日志文件名
logpath = /usr/local/mongodb/logs/mongodb.log
#使用追加的方式写日志
logappend=true  
#最大同时连接数 ,默认2000  
maxConns=100 
#这样就可外部访问了 
bind_ip = 0.0.0.0  
journal=true #每次写入会记录一条操作日志
#storageEngine=wiredTiger  #存储引擎有mmapv1、wiretiger、mongorocks
#noauth=true #不启用验证  
#auth = true #启用验证(首次不要加上权限auth=true，需要先创建用户后再更改)

简单的参数说明： 
–logpath 日志文件路径 
–master 指定为主机器 
–slave 指定为从机器 
–source 指定主机器的IP地址 
–pologSize 指定日志文件大小不超过64M.因为resync是非常操作量大且耗时，最好通过设置一个足够大的oplogSize来避免resync(默认的 oplog大小是空闲磁盘大小的5%)。 
–logappend 日志文件末尾添加 
–port 启用端口号 
–fork 在后台运行 
–only 指定只复制哪一个数据库 
–slavedelay 指从复制检测的时间间隔 
–auth 是否需要验证权限登录(用户名和密码) 
–noauth 不需要验证权限登录(用户名和密码) 

命令启动mongod --config /usr/local/mongodb/bin/mongodb.conf
关闭mongod:>use admin.       >db.shutdownServer();
下载Robo 3T，免费图形工具https://robomongo.org/download


设置开机启动：
vim /etc/systemd/system/mongodb.service
[Unit]
Description=mongodb 
After=network.target remote-fs.target nss-lookup.target
[Service]
Type=forking
ExecStart=/usr/local/mongodb/bin/mongod --config /usr/local/mongodb/bin/mongodb.conf
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/usr/local/mongodb/bin/mongod --shutdown --config /usr/local/mongodb/bin/mongodb.conf
PrivateTmp=true
[Install]
WantedBy=multi-user.target

#启动服务
systemctl start mongodb.service  
#关闭服务  
systemctl stop mongodb.service  
#开机启动  
systemctl enable mongodb.service 










2.基本使用
进入mongodb shell：
bin/mongo
添加管理员用户和密码
db.createUser({user:"admin",pwd:"Admin@01",roles:[{role:"userAdminAnyDatabase",db:"admin"}]})
db.auth('admin','Admin@01')（带密码登录）
创建数据库和普通用户（实际代码中连接数据库必须单独创建用户并赋予相应权限！！！）：
use xizang
db.createUser({
    user:"用户账号",pwd:"用户密码",
    roles:[{role:"权限",db:"库名"}]
})
db.createUser({
    user:"sccddw",pwd:"sccddw",
    roles:[{role:"readWrite",db:"xizang"}]
})


创建数据库：
Use test

查看数据库
show dbs

插入数据
db.test.insert({"name":"zwj"})

删除数据库(先use数据库)
db.dropDatabase()

创建集合
db.createClollection(name, options) #options可选
Options参数：
	capped 如果为 true，则创建固定集合。固定集合是指有着固定大小的集合，当达到最大值时，它会自动覆盖最早的文档。当该值为 true 时，必须指定 size 参数。
	autoIndexId（可选）如为 true，自动在 _id 字段创建索引。默认为 false。
	size（可选）为固定集合指定一个最大值（以字节计）。如果 capped 为 true，也需要指定该字段。
	max（可选）指定固定集合中包含文档的最大数量。

查看collections
show collections

删除集合
db.xxx.drop() #xxx为集合名

插入文档
db.xxx.insert(document)

查看文档
db.xxx.find() # 当数据过多时输入it可以查看更多。

更新文档
db.xxx.update(
<query>,
   <update>,
   {
     upsert: <boolean>,
     multi: <boolean>,
     writeConcern: <document>
   }
)
参数说明：
query : update的查询条件，类似sql update查询内where后面的。
update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的
upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。
multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。
writeConcern :可选，抛出异常的级别。
db.test.update({"name":"zwj"},{$set:{"name":"zwj"})

删除文档
db.collection.remove(
   <query>,
   {
     justOne: <boolean>,
     writeConcern: <document>
   }
)
参数说明：
query :（可选）删除的文档的条件。
justOne : （可选）如果设为 true 或 1，则只删除一个文档，如果不设置该参数，或使用默认值 false，则删除所有匹配条件的文档。
writeConcern :（可选）抛出异常的级别。
Db.test.remove({"name":"zww"})

查询文档：
db.test.find(query, projection)
query ：可选，使用查询操作符指定查询条件。
projection ：可选，使用投影操作符指定返回的键。查询时返回文档中所有键值， 只需省略该参数即可（默认省略）。
db.test.find().pretty()
pretty()方法以格式化的方式来显示所有文档。

Mongodb与关系型数据库语句比较：
db.col.find({"by":"菜鸟教程"}).pretty()	where by = '菜鸟教程'
db.col.find({"likes":{$lt:50}}).pretty()	where likes < 50
db.col.find({"likes":{$ne:50}}).pretty()	where likes != 50

AND条件
db.col.find({key1:value1, key2:value2}).pretty()

OR条件
db.col.find(
   {
      $or: [
         {key1: value1}, {key2:value2}
      ]
   }
).pretty()

limit() 方法
db.col.find({},{"title":"zzz"}).limit(2)
skip()方法来跳过指定数量的数据
db.col.find({},{"title":"zzz"}).limit(1).skip(1) //只会显示第二条文档数据

排序：
db.test.find().sort({"name":1}) #数据按字段name的升序排列，-1则为降序排列。

索引
db.test.createIndex({"name":-1}, options)
Key 值为你要创建的索引字段，1为指定按升序创建索引，如果你想按降序来创建索引指定为-1即可.
Options列表：
background  建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引，即增加"background"可选参数。"background" 默认值为false。
unique  建立的索引是否唯一。指定为true创建唯一索引。默认值为false.
name  索引的名称。如果未指定，MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称。
dropDups  3.0+版本已废弃。在建立唯一索引时是否删除重复记录,指定 true 创建唯一索引。默认值为 false.
sparse  对文档中不存在的字段数据不启用索引；这个参数需要特别注意，如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档.默认值为 false.
expireAfterSeconds  指定一个以秒为单位的数值，完成 TTL设定，设定集合的生存时间。
v  索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本。
weights  索引权重值，数值在 1 到 99,999 之间，表示该索引相对于其他索引字段的得分权重。
default_language  对于文本索引，该参数决定了停用词及词干和词器的规则的列表。 
language_override  对于文本索引，该参数指定了包含在文档中的字段名，语言覆盖默认.默认为英语
db.test.find({"name":"zwj"}).explain()


聚合查询
db.text.aggregate([{$group : {_id : "$by_user", num_tutorial : {$sum : 1}}}])
$sum	计算总和
$avg	计算平均值
$min	获取集合中所有文档对应值得最小值
$max	获取集合中所有文档对应值得最大值
$first	根据资源文档的排序获取第一个文档数据
$last	根据资源文档的排序获取最后一个文档数据
$project：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及嵌套文档。
$match：用于过滤数据，只输出符合条件的文档。$match使用MongoDB的标准查询操作。
$limit：用来限制MongoDB聚合管道返回的文档数。
$skip：在聚合管道中跳过指定数量的文档，并返回余下的文档。
$unwind：将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值。
$group：将集合中的文档分组，可用于统计结果。
$sort：将输入文档排序后输出。
$geoNear：输出接近某一地理位置的有序文档。

数据备份
>mongodump -h dbhost -d dbname -o dbdirectory
-h：
MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017
-d：
需要备份的数据库实例，例如：test
-o：
备份的数据存放位置

数据恢复
mongorestore -h <hostname><:port> -d dbname <path>
--host <:port>, -h <:port>：
MongoDB所在服务器地址，默认为： localhost:27017
--db , -d ：
需要恢复的数据库实例，例如：test，当然这个名称也可以和备份时候的不一样，比如test2
--drop：
恢复的时候，先删除当前数据，然后恢复备份的数据。就是说，恢复后，备份后添加修改的数据都会被删除，慎用哦！
<path>：
mongorestore 最后的一个参数，设置备份数据所在位置，例如：c:\data\dump\test。
你不能同时指定 <path> 和 --dir 选项，--dir也可以设置备份目录。
--dir：
指定备份的目录

MongoDB 监控
>mongostat
mongotop用来跟踪一个MongoDB的实例
>mongotop










3.java api
java的MongoDB驱动当前一共有4个库,优先推荐mongodb-driver-sync
mongodb-driver-sync
这个库只有MongoCollection接口，并且不包含废弃的API。
mongodb-driver-legacy
这个驱动带有com.mongodb.MongoClient这个入口，核心类是com.mongodb.DB, com.mongodb.DBCollection和com.mongodb.DBCursor，很多网上的样例用的是这两个类。
mongodb-driver-async
同步的Java驱动
maven仓库在：https://mongodb.github.io/mongo-java-driver/ 
<dependencies>
    <dependency>
        <groupId>org.mongodb</groupId>
        <artifactId>mongodb-driver-sync</artifactId>
        <version>3.10.1</version>
    </dependency>
</dependencies>
API文档：http://mongodb.github.io/mongo-java-driver/3.10/driver/getting-started/installation/










4.集群搭建
1）副本集模式
mongodb的副本集相当于具有自动故障恢复的主从集群，主从集群和副本集最明显的特征为副本集没有固定的“主节点”，整个集群会通过一定的算法选举出主节点，目前MongoDB官方已经不建议使用主从模式了，在主从模式下，如果主数据库宕机，从数据库无法自动接管主数据库，从而无法接入数据，取而代之的就是MongoDB副本集模式，主服务器负责整个副本集的读写，副本集定期同步数据备份，副本集中的副本节点在主节点挂掉后通过心跳机制检测到后副本节点就会选举一个新的主服务器，这一切对于应用服务器无需关心。
2）复制原理
mongodb的复制至少需要两个节点。其中一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据。
mongodb各个节点常见的搭配方式为：一主一从、一主多从。
主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。
3）副本集特征：
N 个节点的集群
任何节点可作为主节点
所有写入操作都在主节点上
自动故障转移
自动恢复
4）Bully(ˈbʊli,拼音buli)算法
如果副本集中主节点宕掉后，需要使用bully算法进行选举主节点，其主要思想为每个成员均可以声明自己为主节点并通知其他节点，别的节点可以选择接受这个声明或是拒绝并进入主节点竞争，只有被其他节点接受的节点才可以当主节点，
节点按照一些属性来判断谁应该胜出。这个属性可以是一个静态ID，也可以是更新的度量像最近一次事务ID（最新的节点会胜出）。
官方描述：
得到每个服务器节点的最后操作时间戳。每个mongodb都有oplog机制会记录本机的操作，方便和主服务器进行对比数据是否同步还可以用于错误恢复。
如果集群中大部分服务器down机了，保留活着的节点都为 secondary状态并停止，不选举了。
如果集群中选举出来的主节点或者所有从节点最后一次同步时间看起来很旧了，停止选举等待人来操作。
如果上面都没有问题就选择最后操作时间戳最新（保证数据是最新的）的服务器节点作为主节点。
5）Replica Set成员
一个Replica Set中的成员角色有三种：Primary，Secondary和Arbiter(仲裁节点)。
Primary：接收来自客户端的所有的写操作，一个Replica Set中有且只有一个Primary。Primary如果宕掉，Replica Set会自动选举一个Secondary成为Primary。Primary将它data sets的所有操作都记录到oplog中。
Secondary:Secondary从Primary复制oplog，然后将oplog中的操作应用到自己的data sets。Secondary和Primary之间是异步复制，也就是Secondary中的数据可能不是最新的。默认情况下，Secondary不可读不可写，但是可以通过设置运行客户端从Secondary读。
一个Replica Set可以最多拥有12个成员，但是只有7个成员可以同时参与投票选举成为Primary，如果成员数量超过12，就需要使用Master-Slave主从复制方式。
部署一个Replica Set至少需要三个成员，一个Arbiter，一个Secondary和一个Primary或者一个Primary，两个Secondary。

6）配置文件
除了配置文件不同其它一样。
配置文件不同处：
#副本集名称
replSet=rep

7）配置集群：
启动数据库：mongod --config /usr/local/mongodb/bin/mongodb.conf
副本集部署
挑选任意一台mongodb进行登录
#bin/mongo
注意看，member中的项目有个stateStr字段表示节点角色，其值为
PRIMARY： 表示主节点
SECONDARY： 表示从节点
ARBITER： 表示仲裁节点

>use admin                #切换到admin数据库
 #定义副本集配置,_id设置为副本集名称
>config = {_id:"rep",members:[               
{_id:0,host:"192.168.11.46:27017"},
{_id:1,host:"192.168.11.94:27017"},
{_id:2,host:"192.168.11.183:27017"},]
}
>rs.initiate(config);        # 初始化副本集配置
> rs.status();               # 查看副本集状态
> rs.conf()                  # 查看副本集的配置信息

关闭副本集：
>rs.stepdown() //  将当前主库“降级”
>use admin
>db.shutdownServer() // 这个只能关闭当前实例

8)测试
在主节点创建数据库，并创建集合，插入文档
就是use tested, db.ceateCollection("test"),db.test.insert({"xxx":"","ccc":"vvv"})
登录另外一台服务器mongo数据库：
#mongodb默认是从主节点读写数据的，副本节点上不允许读，需要设置副本节点可以读。
在此服务器执行下面的命令：
> rs.secondaryOk() (db.getMongo().setSlaveOk(); )           #设置副本节点可读
>show dbs;                             #可以看到在之前节点创建的数据库
数据已经同步到secondary上，但是无法在secondary上进行数据的增删改操作。

故障转移测试
在主节点执行：
ps -ef | grep mongod
kill -9 xxx //关闭服务器
在另一台服务器登录mongod
rs.status() #查看服务器状态，可以看到刚刚被关闭的服务器health为0.

如果考虑到主服务器的复制压力过大，可以制作仲裁节点，其中的仲裁节点不存储数据，只是负责故障转移的群体投票，这样就少了数据复制的压力。
删除节点：
rs.remove("192.168.11.94:27017")            #删除节点
添加节点
rs.add("192.168.11.94:27017")                #添加节点
rs.addArb("192.168.11.128:27017")               #添加arbiter节点

9)mongodb选举
成员有优先级，优先级为0的成员不能成为主节点，也不能谋求选举。
修改节点的优先级可以触发重新选举,这样可以人工指定主节点。
cfg=rs.conf();
cfg.members[0].priority=1
cfg.members[1].priority=1
cfg.members[2].priority=10
rs.reconfig(cfg);
需要注意的是，修改节点优先级需要登录Master节点运行。
仲裁节点不存储数据，只是用于投票。节点一旦以仲裁者的身份加入集群，他就只能是仲裁者，无法将仲裁者配置为非仲裁者。
一个集群最多只能使用一个仲裁者，额外的仲裁者拖累选举新Master节点的速度。
当选规则：
1）票数最高，且获得大多数n/2 + 1，如果节点不够，则集群节点没有主节点全部在只读状态。
2）票数一样，数据新的节点获胜，新旧通过操作日志oplog来对比。
（查看：https://docs.mongodb.com/manual/reference/replica-set-protocol-versions/）

10）分片副本集集群
sharding集群包含3个角色：mongos，configsvr，shardsvr
shardsvr用于存储实际的数据块
configsvr存储了整个 ClusterMetadata即集群元数据
mongos 即Routers前端路由，客户端由此接入，且让整个集群看上去像单一数据库，前端应用可以透明使用。

先kill -9之前启动的mongodb。
cp之前解压的mongodb目录，拷贝3份，作为shard分片1、2，原来的作为config配置节点，还有一份做mongos(即路由router)。分片副本集的shard1、shard2、config都是副本集。
修改配置文件
分片shard1：
端口改为27018
#副本集名称
replSet=shard1
#declare this is a shard db of a cluster;
shardsvr = true
分片shard2：
端口改为27019
#副本集名称
replSet=shard2
#declare this is a shard db of a cluster;
shardsvr = true
配置节点config：
端口改为27020
#副本集名称
replSet=config
#declare this is a shard db of a cluster;
configsvr = true

分别启动第一套副本集shard1,第二套副本集shard2，配置副本集config
然后登陆shell:
#./mongodb_shard1/bin/mongo -port 27018
>config = {_id:"shard1",members:[               
{_id:0,host:"192.168.11.46:27018"},
{_id:1,host:"192.168.11.94:27018"},
{_id:2,host:"192.168.11.183:27018"},]
}
>rs.initiate(config);        # 初始化副本集配置
> rs.status();               # 查看副本集状态
rs.addArb("192.168.11.128:27018")               #添加arbiter节点

#./mongodb_shard2/bin/mongo -port 27019
>config = {_id:"shard2",members:[               
{_id:0,host:"192.168.11.46:27019"},
{_id:1,host:"192.168.11.94:27019"},
{_id:2,host:"192.168.11.183:27019"},]
}
>rs.initiate(config);        # 初始化副本集配置
> rs.status();               # 查看副本集状态
rs.addArb("192.168.11.128:27019")               #添加arbiter节点

#./mongodb_config/bin/mongo -port 27020
>config = {_id:"config",members:[               
{_id:0,host:"192.168.11.46:27020"},
{_id:1,host:"192.168.11.94:27020"},
{_id:2,host:"192.168.11.183:27020"},]
}
>rs.initiate(config);        # 初始化副本集配置
> rs.status();               # 查看副本集状态
// config集群不需要仲裁节点

配置router（router可以有多个，配置是一样的router之间没有关系）：
创建mongos.config
vim mongodb_mongos/bin/mongos.conf 
#mongos不存储数据所以只需要设置log目录
logpath=/usr/local/mongodb_mongos/logs/mongos.log 
logappend = true
port = 27017
fork = true
maxConns=20000
bind_ip=0.0.0.0
configDB = config/192.168.11.46:27020,192.168.11.94:27020,192.168.11.183:27020 #这里的ip是config副本集的ip, config是配置副本集的名字

启动mongos:
 /usr/local/mongodb_mongos/bin/mongos --config /usr/local/mongodb_mongos/bin/mongos.conf
连接mongo：
mongodb_mongos/bin/mongo --port 27017
切换数据库：
添加加分片：
mongos>sh.addShard("shard1/192.168.11.46:27018,192.168.11.94:27018,192.168.11.183:27018");
mongos>sh.addShard("shard2/192.168.11.46:27019,192.168.11.94:27019,192.168.11.183:27019");
mongos>sh.status() # 查看状态
mongos>sh.enableSharding("test_db") # 开启test_db库的分片
#添加分片规则，根据"id"对user集合进行hash分片，策略有两种：hash策略、范围策略，分片策略每个集合只能有一个
#分片的集合在片键上都必须建索引，这是MongoDB自动执行的
mongos>sh.shardCollection("test_db.user",{"id":"hashed"}) 
 sh.shardCollection("test_db.user",{"id":1}) #id加范围策略

测试：
mongos>use test_db;
mongos> for(i=1;i<=5000;i++){db.user.insert({"id":i,"name":"jack"+i})}  # 循环生成5000条数据
# 在shard1、shard2, use test_db; db.user.count();可以看到两边数据和为5000

如果要测试范围策略，数据较小需要修改chunksize:
use config; # 切换到config库
db.settings.save({_id:"chunksize", value: 1}) #修改为1M

springboot连接,直接连接router：
uri: mongodb://root:uestc%40root@192.168.11.160:27017,192.168.11.12:27017/test_db









5.开启授权
#注意：先在不开启认证的情况下，创建用户，之后关闭服务，然后再开启认证，才生效。
副本集下必须在master上才能执行如下命令，数据会自动同步到slave节点，每个副本集的master都要创建包括shard1、shard2、config.
db.createUser({
	user:'root',
	pwd:'uestc@root',
	customData:{description:"管理员root"},
	roles:[{
		'role':'root',
		'db':'admin'
	}]
})

db.createUser({
	user:'zwj',
	pwd:'sccddw123456',
	roles:[{
		'role':'readWrite',
		'db':'test_db'
	}]
})

db.createUser({
	user:'zwj',
	pwd:'sccddw123456',
	roles:[{
		'role':'dbOwner',
		'db':'test_db'
	}]
})

'role':'readWrite', ///读写账号
显示用户：>show users

mongodb需要通过keyfiles来解决实现副本集间的相互信任问题，不然--auth，此时登录主节点会失败（实际登录的是OTHER节点）
//创建keyfile文件
openssl rand -base64 741 > /usr/local/mongodb/keyfile（取决于你放keyfile的路径）
注意，每个节点必须要用同一份keyfile，将这个keyfile复制到不同部署节点的主机上。并且chmod 600 keyfile.权限错误会造成无法启动
修改配置文件
#vi mongodb.conf
//添加
keyFile=/usr/local/mongodb/keyfile
auth=true
(注意：chmod 600 keyfile)

mongos.conf
只需要添加：keyFile=/usr/local/mongodb_mongos/keyfile
(注意：chmod 600 keyfile)

启动mongodb
#mongod --config /usr/local/mongodb/bin/mongodb.conf 
问题：如果出现：waiting until server is ready for connections forked process: 2033 
解决：
#删除data目录下的mongod.lock文件. Kill -9 2033. 
#bin目录下：./mongod  --repair
如果删除了.lock或没有.lock还是报错
chmod 400 keyFile(仅所有者可读）
进入之后，会显示rep:Secondary或PRIMARY，但此时没有授权，无法进行数据库操作
>db.auth("root","uestc@root")
>db.getMongo().setSlaveOk();

service mongodb_config restart
service mongodb_shard1 restart
service mongodb_shard2 restart

chmod 600 mongodb_config/keyfile 
chmod 600 mongodb_shard1/keyfile 
chmod 600 mongodb_shard2/keyfile 
（注意：出现无法连接的情况先chmod 600 keyfile）

给mongos添加账号（这个只需要在一个mongos操作就行）:
登录：
#mongodb_mongos/bin/mongo
mongos > use admin
mongos > db.createUser({
	user:'root',
	pwd:'uestc@root',
	customData:{description:"管理员root"},
	roles:[{
		'role':'root',
		'db':'admin'
	}]
})
添加普通用户
mongos > use admin
mongos > db.auth("root", "uestc@root")
mongos > use test_db
db.createUser({
	user:'zwj',
	pwd:'sccddw123456',
	roles:[{
		'role':'dbOwner',
		'db':'test_db'
	}]
})







6.集群使用
Springboot连接mongodb:
<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-mongodb</artifactId>
        </dependency>
application.properties中添加配置:
// spring.data.mongodb.uri=mongodb://user:pwd@ip1:port1,ip2:port2/database
// 副本集连接
spring.data.mongodb.uri=mongodb://root:uestc%40root@192.168.11.167:27017,192.168.11.40:27017,192.168.11.45:27017/
// 分片副本集连接mongos:
spring.data.mongodb.uri=mongodb://zwj:sccddw123456@192.168.11.160:27017,192.168.11.12:27017/test_db

spring.data.mongodb.database=test_rep
问题：authentication failed
1、不要使用root登录。 
2、登录数据库
>use admin 
>db.createUser({
	user:'tt',
	pwd:'tt',
	roles:[{
		'role':'dbOwner',
		'db':'test_rep'
	}]
})
3.然后使用tt用户登录
注意：一定要切换到admin数据库去再创建用户,一定要使用spring.data.mongodb.database指定数据库。

entity文件：
// @Document(collection = "test_collection") 
@Document("test_collection") 
public class User {
    private String name;
    private String age;

    public String toString(){
        return "name:"+name+","+"age:"+age;
    }
}
List list = mongoTemplate.find(new Query(Criteria.where("name").is("zwj")),User.class);
或
List list = mongoTemplate.find(new Query(Criteria.where("name").is("zwj")),User.class,"test_collection");//可以指定集合名













7.windows安装
https://www.mongodb.com/download-center#community
安装完成后
C 盘安装了 mongodb，现在让我们创建一个 mongodbData 的目录然后在 data 目录里创建 db 目录。
c:\>cd c:\
c:\>mkdir mongodbData
c:\>cd data
c:\data>mkdir db
c:\data>cd db
c:\data\db>

命令行下运行 MongoDB 服务器
>cd C:\Program Files\MongoDB\Server\3.6\bin\
>mongod --dbpath c:\mongodbData\db


配置 MongoDB 服务
创建目录，执行下面的语句来创建数据库和日志文件的目录
mkdir c:\mongodbData\db
mkdir c:\mongodbData\log

创建配置文件
创建一个配置文件。该文件必须设置systemLog.path参数，包括一些附加的配置选项更好。
创建一个配置文件位于 C:\Program Files\MongoDB\mongod.cfg，其中指定 systemLog.path 和 storage.dbPath。具体配置内容如下：
systemLog:
    destination: file
    path: c:\mongodbData\log\mongod.log
storage:
    dbPath: c:\mongodbData\db

>cd C:\Program Files\MongoDB\Server\3.6\(注意：请以管理员打开cmd)
>bin\mongod.exe --config "C:\Program Files\MongoDB\Server\3.6\mongod.cfg" --install --serviceName "mongodb"

启动MongoDB服务
net start mongodb
关闭MongoDB服务
net stop mongodb
移除 MongoDB 服务
>cd C:\Program Files\MongoDB\Server\3.6\
>bin\mongod.exe --remove

MongoDB shell：
> mongo













8.对象映射编程
创建好对象MongoDevice：
@Data
@Document("mongoSensorData") // 集合名为mongoSensorData,要对象名一致，除了首字母不用大写
// 复合索引,不过建议在命令行建
//@CompoundIndex(def = "{'userId': 1, 'nickname': -1}")
public class MongoSensorData implements Serializable {
    @Id
    private BigInteger id; // 主键
    @Indexed
    private String deviceCode = null;
    @Field("acquisitionTime") // 当属性与MongoDB字段的名字，不一致时可以使用Field做映射
    private String acquisitionTime;
    @JsonFormat(shape = JsonFormat.Shape.STRING, pattern = "yyyy-MM-dd HH:mm:ss", timezone = "GMT+8")
    @DateTimeFormat(pattern = "yyyy-MM-dd HH:mm:ss")
    private Date createTime = new Date();
}
在dao目录下创建接口文件：
SensorDataRepository
public interface SensorDataRepository extends MongoRepository<MongoSensorData, String> {

	// 分页查询
    Page<MongoSensorData> findByAcquisitionTimeContains(String acquisitionTime, Pageable pageable);

//    @Query("{'acquisitionTime': { $regex: '^?0'} }") // 自定义sql
//    List<MongoSensorData> findSensorDataQuery(String acquisitionTime);
}
在service创建MongoSensorDataServiceImpl
@Service
public class MongoSensorDataServiceImpl {
    @Autowired
    SensorDataRepository sensorDataRepository;

    @Autowired
    MongoTemplate mongoTemplate;

    /**
     * 保存数据
    **/
    public void save(MongoSensorData sensorData) {
        MongoSensorData s = sensorDataRepository.save(sensorData);
    }

    public void saveAll(List<MongoSensorData> list) {
        sensorDataRepository.saveAll(list);
    }

    public Page<MongoSensorData> pageFindByAcquisitionTime(String acquisitionTime , int current, int pageSize) {
        return sensorDataRepository.findByAcquisitionTimeContains(acquisitionTime, PageRequest.of(current, pageSize));
    }

	/**
     * 多集合联合查询   
    **/
    public List<Map> lookupOperation(String acquisitionTime) {
        LookupOperation lookupOperation = LookupOperation.newLookup().
                from("mongoDevice"). //关联从表名
                localField("deviceCode"). //主表关联字段
                foreignField("deviceCode"). //从表关联的字段
                as("SensorDataAndDevice"); //查询结果表的别名

        // 匹配id条件
        MatchOperation matchOperation = new MatchOperation(Criteria.where("acquisitionTime").is(acquisitionTime));
        SortOperation sortOperation = new SortOperation(Sort.by(Sort.Order.desc("createTime")));
        Aggregation aggregation = Aggregation.newAggregation(lookupOperation, matchOperation, sortOperation);
        List<Map> res = mongoTemplate.aggregate(aggregation, "mongoSensorData", Map.class).getMappedResults();

        return res;
    }

}





























